{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e609201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sales for Region A: 11.8\n",
      "Mean sales for Region B: 20.2\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "def calculate_mean_sales(region_sales):\n",
    "    total_sales = sum(region_sales)\n",
    "    num_data_points = len(region_sales)\n",
    "    mean_sales = total_sales / num_data_points\n",
    "    return mean_sales\n",
    "\n",
    "# Given data\n",
    "region_a_sales = [10, 15, 12, 8, 14]\n",
    "region_b_sales = [18, 20, 16, 22, 25]\n",
    "\n",
    "# Calculate mean sales for each region\n",
    "mean_sales_region_a = calculate_mean_sales(region_a_sales)\n",
    "mean_sales_region_b = calculate_mean_sales(region_b_sales)\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean sales for Region A:\", mean_sales_region_a)\n",
    "print(\"Mean sales for Region B:\", mean_sales_region_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a5bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of the survey responses: 4\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "import statistics\n",
    "\n",
    "survey_responses = [4, 5, 2, 3, 5, 4, 3, 2, 4, 5]\n",
    "mode_value = statistics.mode(survey_responses)\n",
    "\n",
    "print(\"Mode of the survey responses:\", mode_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b642e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median salary for Department A: 5750.0\n",
      "Median salary for Department B: 5500\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "def calculate_median(salary_data):\n",
    "    n = len(salary_data)\n",
    "    sorted_data = sorted(salary_data)\n",
    "    \n",
    "    if n % 2 == 0:\n",
    "        # If the number of elements is even, take the average of the two middle values\n",
    "        median = (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2\n",
    "    else:\n",
    "        # If the number of elements is odd, take the middle value\n",
    "        median = sorted_data[n // 2]\n",
    "    \n",
    "    return median\n",
    "\n",
    "# Salary data for Department A\n",
    "department_a_salaries = [5000, 6000, 5500, 7000]\n",
    "median_a = calculate_median(department_a_salaries)\n",
    "print(\"Median salary for Department A:\", median_a)\n",
    "\n",
    "# Salary data for Department B\n",
    "department_b_salaries = [4500, 5500, 5800, 6000, 5200]\n",
    "median_b = calculate_median(department_b_salaries)\n",
    "print(\"Median salary for Department B:\", median_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0468b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of the stock prices is: 1.3000000000000007\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "stock_prices = [25.5, 24.8, 26.1, 25.3, 24.9]\n",
    "\n",
    "# Calculate the range\n",
    "price_range = max(stock_prices) - min(stock_prices)\n",
    "\n",
    "print(\"The range of the stock prices is:\", price_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56791339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: 0.8757511375750132\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "import numpy as np\n",
    "\n",
    "# Advertising Expenditure (in thousands)\n",
    "advertising_expenditure = np.array([10, 15, 12, 8, 14])\n",
    "\n",
    "# Sales (in thousands)\n",
    "sales = np.array([25, 30, 28, 20, 26])\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(advertising_expenditure, sales)[0, 1]\n",
    "\n",
    "print(\"Correlation Coefficient:\", correlation_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11349e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of heights: 8.591246929842246\n"
     ]
    }
   ],
   "source": [
    "#Q7\n",
    "import statistics\n",
    "\n",
    "# Heights data\n",
    "heights = [160, 170, 165, 155, 175, 180, 170]\n",
    "\n",
    "# Calculate the standard deviation\n",
    "std_dev = statistics.stdev(heights)\n",
    "\n",
    "print(\"Standard deviation of heights:\", std_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acbe19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Tenure:  [2 3 5 4 6 2 4]\n",
      "Actual Job Satisfaction:  [7 8 6 9 5 7 6]\n",
      "Predicted Job Satisfaction:  [7.65957447 7.19148936 6.25531915 6.72340426 5.78723404 7.65957447\n",
      " 6.72340426]\n",
      "Slope (Coefficient):  -0.4680851063829787\n",
      "Intercept:  8.595744680851062\n"
     ]
    }
   ],
   "source": [
    "#Q8\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 1: Data preparation\n",
    "employee_tenure = np.array([2, 3, 5, 4, 6, 2, 4]).reshape(-1, 1)\n",
    "job_satisfaction = np.array([7, 8, 6, 9, 5, 7, 6])\n",
    "\n",
    "# Step 2: Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(employee_tenure, job_satisfaction)\n",
    "\n",
    "# Step 3: Make predictions\n",
    "predicted_satisfaction = model.predict(employee_tenure)\n",
    "\n",
    "# Optional: Check the coefficients and intercept of the linear regression model\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Step 4: Print the results\n",
    "print(\"Employee Tenure: \", employee_tenure.flatten())\n",
    "print(\"Actual Job Satisfaction: \", job_satisfaction)\n",
    "print(\"Predicted Job Satisfaction: \", predicted_satisfaction)\n",
    "\n",
    "# Optional: Print the slope and intercept\n",
    "print(\"Slope (Coefficient): \", slope)\n",
    "print(\"Intercept: \", intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7179817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a significant difference in the mean recovery times between the two medications.\n"
     ]
    }
   ],
   "source": [
    "#Q9\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for Medication A and Medication B\n",
    "medication_a = [10, 12, 14, 11, 13]\n",
    "medication_b = [15, 17, 16, 14, 18]\n",
    "\n",
    "# Perform the one-way ANOVA\n",
    "result = stats.f_oneway(medication_a, medication_b)\n",
    "\n",
    "# Extract the ANOVA test statistic and p-value from the result\n",
    "test_statistic, p_value = result.statistic, result.pvalue\n",
    "\n",
    "# Determine if there is a significant difference between the groups\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in the mean recovery times between the two medications.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in the mean recovery times between the two medications.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04cd2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th percentile of feedback ratings: 8.75\n"
     ]
    }
   ],
   "source": [
    "#Q10\n",
    "import numpy as np\n",
    "\n",
    "feedback_ratings = [8, 9, 7, 6, 8, 10, 9, 8, 7, 8]\n",
    "\n",
    "# Calculate the 75th percentile\n",
    "percentile_75 = np.percentile(feedback_ratings, 75)\n",
    "\n",
    "print(\"75th percentile of feedback ratings:\", percentile_75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f659d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-sample t-test:\n",
      "Sample mean: 10.15\n",
      "Hypothesized mean: 10.0\n",
      "t-statistic: 1.5126584522688367\n",
      "p-value: 0.19077595151110102\n",
      "The mean weight does not differ significantly from 10 grams.\n"
     ]
    }
   ],
   "source": [
    "#Q11\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Given sample of product weights\n",
    "weights = np.array([10.2, 9.8, 10.0, 10.5, 10.3, 10.1])\n",
    "\n",
    "# Hypothesized mean weight (H0 assumption)\n",
    "hypothesized_mean = 10.0\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_stat, p_value = ttest_1samp(weights, hypothesized_mean)\n",
    "\n",
    "# Define significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the results\n",
    "print(\"One-sample t-test:\")\n",
    "print(\"Sample mean:\", np.mean(weights))\n",
    "print(\"Hypothesized mean:\", hypothesized_mean)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for statistical significance\n",
    "if p_value < alpha:\n",
    "    print(\"The mean weight differs significantly from 10 grams.\")\n",
    "else:\n",
    "    print(\"The mean weight does not differ significantly from 10 grams.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1045499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 6.110658166925435\n",
      "P-value: 0.19103526314060293\n",
      "There is no significant difference in click-through rates between the two designs.\n"
     ]
    }
   ],
   "source": [
    "#Q12\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Click-through data for each design\n",
    "design_a = [100, 120, 110, 90, 95]\n",
    "design_b = [80, 85, 90, 95, 100]\n",
    "\n",
    "# Create a contingency table\n",
    "observed_data = np.array([design_a, design_b])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p_value, _, _ = chi2_contingency(observed_data)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in click-through rates between the two designs.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in click-through rates between the two designs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8738468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 7.90\n",
      "Standard Deviation: 1.20\n",
      "Critical t-value: 2.262\n",
      "Margin of Error: 0.86\n",
      "95% Confidence Interval: [7.04, 8.76]\n"
     ]
    }
   ],
   "source": [
    "#Q13\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "data = [7, 9, 6, 8, 10, 7, 8, 9, 7, 8]\n",
    "sample_size = len(data)\n",
    "\n",
    "# Step 1: Calculate the sample mean and standard deviation\n",
    "sample_mean = np.mean(data)\n",
    "sample_std = np.std(data, ddof=1)  # Use ddof=1 for sample standard deviation (Bessel's correction)\n",
    "\n",
    "# Step 2: Determine the critical t-value (two-tailed) for 95% confidence level\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = sample_size - 1\n",
    "critical_t = stats.t.ppf((1 + confidence_level) / 2, degrees_of_freedom)\n",
    "\n",
    "# Step 3: Calculate the margin of error\n",
    "margin_of_error = critical_t * (sample_std / np.sqrt(sample_size))\n",
    "\n",
    "# Step 4: Calculate the lower and upper bounds of the confidence interval\n",
    "lower_bound = sample_mean - margin_of_error\n",
    "upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "# Output the results\n",
    "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
    "print(f\"Standard Deviation: {sample_std:.2f}\")\n",
    "print(f\"Critical t-value: {critical_t:.3f}\")\n",
    "print(f\"Margin of Error: {margin_of_error:.2f}\")\n",
    "print(f\"95% Confidence Interval: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a621b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 0.4999999999999999\n",
      "Intercept: -2.8999999999999986\n"
     ]
    }
   ],
   "source": [
    "#Q14\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data\n",
    "temperature = np.array([20, 22, 23, 19, 21]).reshape(-1, 1)  # Reshape to a 2D array for scikit-learn\n",
    "performance = np.array([8, 7, 9, 6, 8])\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(temperature, performance)\n",
    "\n",
    "# Get the coefficients (slope and intercept) of the regression line\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Slope:\", slope)\n",
    "print(\"Intercept:\", intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aa69bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interquartile Range (IQR) of customer ages: 22.5\n"
     ]
    }
   ],
   "source": [
    "#Q16\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Create a list of customer ages\n",
    "ages = [25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "\n",
    "# Step 3: Sort the list of ages in ascending order\n",
    "sorted_ages = sorted(ages)\n",
    "\n",
    "# Step 4: Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "Q1 = np.percentile(sorted_ages, 25)\n",
    "Q3 = np.percentile(sorted_ages, 75)\n",
    "\n",
    "# Step 5: Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(\"Interquartile Range (IQR) of customer ages:\", IQR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfbdec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test statistic: 9.696947935368053\n",
      "p-value: 0.007840333026249539\n",
      "There is a significant difference in the median accuracy scores between the algorithms.\n"
     ]
    }
   ],
   "source": [
    "#Q17\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Accuracy scores for each algorithm\n",
    "algorithm_A = [0.85, 0.80, 0.82, 0.87, 0.83]\n",
    "algorithm_B = [0.78, 0.82, 0.84, 0.80, 0.79]\n",
    "algorithm_C = [0.90, 0.88, 0.89, 0.86, 0.87]\n",
    "\n",
    "# Perform the Kruskal-Wallis test\n",
    "statistic, p_value = kruskal(algorithm_A, algorithm_B, algorithm_C)\n",
    "\n",
    "# Output the results\n",
    "print(\"Kruskal-Wallis test statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if there is a significant difference\n",
    "alpha = 0.05  # Set the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in the median accuracy scores between the algorithms.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in the median accuracy scores between the algorithms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be47da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sales for New Prices:\n",
      "Price: 11 dollars => Predicted Sales: 97.80 units\n",
      "Price: 13 dollars => Predicted Sales: 90.79 units\n",
      "Price: 16 dollars => Predicted Sales: 80.27 units\n"
     ]
    }
   ],
   "source": [
    "#Q18\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data\n",
    "price = np.array([10, 15, 12, 8, 14]).reshape(-1, 1)  # Reshape to make it a 2D array\n",
    "sales = np.array([100, 80, 90, 110, 95])\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(price, sales)\n",
    "\n",
    "# Predict sales based on new price values\n",
    "new_prices = np.array([11, 13, 16]).reshape(-1, 1)  # New prices to predict sales for\n",
    "predicted_sales = model.predict(new_prices)\n",
    "\n",
    "print(\"Predicted Sales for New Prices:\")\n",
    "for p, s in zip(new_prices, predicted_sales):\n",
    "    print(f\"Price: {p[0]} dollars => Predicted Sales: {s:.2f} units\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2102792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error of the mean is: 0.31\n"
     ]
    }
   ],
   "source": [
    "#Q19\n",
    "import statistics\n",
    "\n",
    "# Sample data\n",
    "data = [7, 8, 9, 6, 8, 7, 9, 7, 8, 7]\n",
    "\n",
    "# Calculate the standard error of the mean\n",
    "sem = statistics.stdev(data) / (len(data) ** 0.5)\n",
    "\n",
    "print(f\"The standard error of the mean is: {sem:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d63f1dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.767\n",
      "Model:                            OLS   Adj. R-squared:                  0.689\n",
      "Method:                 Least Squares   F-statistic:                     9.872\n",
      "Date:                Tue, 18 Jul 2023   Prob (F-statistic):             0.0516\n",
      "Time:                        20:01:57   Log-Likelihood:                -9.5288\n",
      "No. Observations:                   5   AIC:                             23.06\n",
      "Df Residuals:                       3   BIC:                             22.28\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      12.2012      4.429      2.755      0.070      -1.893      26.296\n",
      "Advertising_Expenditure     1.1524      0.367      3.142      0.052      -0.015       2.320\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.136\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.546\n",
      "Skew:                          -0.267   Prob(JB):                        0.761\n",
      "Kurtosis:                       1.471   Cond. No.                         57.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "#Q20\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Data\n",
    "advertising_expenditure = np.array([10, 15, 12, 8, 14])\n",
    "sales = np.array([25, 30, 28, 20, 26])\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = pd.DataFrame({'Advertising_Expenditure': advertising_expenditure, 'Sales': sales})\n",
    "\n",
    "# Add a constant column for the intercept term in the regression\n",
    "data = sm.add_constant(data)\n",
    "\n",
    "# Fit the multiple regression model\n",
    "model = sm.OLS(data['Sales'], data[['const', 'Advertising_Expenditure']])\n",
    "result = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392db6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
